{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch # library\nimport torch.nn as nn # importing nural network libraries","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T17:03:55.197594Z","iopub.execute_input":"2025-07-06T17:03:55.198287Z","iopub.status.idle":"2025-07-06T17:03:57.252306Z","shell.execute_reply.started":"2025-07-06T17:03:55.198254Z","shell.execute_reply":"2025-07-06T17:03:57.251449Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# class NeuralNetwork(nn.Module): # create class\n#     def __init__(self):\n#         super(NeuralNetwork,self).__init__()\n#         self.fc1 = nn.Linear(1,2) # first layer\n#         #if 1 is given as inout then 2 will be its output\n#         self.fc2 = nn.Linear(3,4) # second layer\n#         # 3 is error term which dont give error needs to learn\n#         #beacus efc1 outputs 2 featues which is the expected input featues for fc2\n#         # but here we gave 3 insted of 2 should give error but didnt\n#         #while creatting output featusr must match inout featues of next layer\n#         self.fc3 = nn.Linear(5,6) # third layer\n\n#     def forward(self,x):\n#         x = torch.relu(self.fc1(x))\n#         x = torch.relu(self.fc2(x))\n#         x = torch.sigmoid(self.fc3(x))\n#         return x\n    \n\n# model = NeuralNetwork()\n\n# model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T17:03:57.253567Z","iopub.execute_input":"2025-07-06T17:03:57.253929Z","iopub.status.idle":"2025-07-06T17:03:57.257945Z","shell.execute_reply.started":"2025-07-06T17:03:57.253904Z","shell.execute_reply":"2025-07-06T17:03:57.257161Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# What You Can Build With PyTorch\n# Image classification (CNNs)\n\n# Language models (RNNs, Transformers)\n\n# GANs for image generation\n\n# Reinforcement learning agents\n\n# Chatbots and translators","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T17:03:57.258760Z","iopub.execute_input":"2025-07-06T17:03:57.258986Z","iopub.status.idle":"2025-07-06T17:03:57.276436Z","shell.execute_reply.started":"2025-07-06T17:03:57.258947Z","shell.execute_reply":"2025-07-06T17:03:57.275731Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"| Term                  | What it is                   |\n| --------------------- | ---------------------------- |\n| **Tensor**            | A multidimensional array     |\n| **Model (nn.Module)** | Your neural network          |\n| **Loss Function**     | Tells how wrong the model is |\n| **Optimizer**         | Adjusts model to improve     |\n| **Autograd**          | Handles gradient calculation |\n","metadata":{}},{"cell_type":"markdown","source":"code:\nclass NeuralNetwork(nn.Module): # create class\n    def __init__(self):\n        super(NeuralNetwork,self).__init__()\n        self.fc1 = nn.Linear(1,2) # first layer\n        #if 1 is given as inout then 2 will be its output\n        self.fc2 = nn.Linear(3,4) # second layer\n        # 3 is error term which dont give error needs to learn\n        #beacus efc1 outputs 2 featues which is the expected input featues for fc2\n        # but here we gave 3 insted of 2 should give error but didnt\n        #while creatting output featusr must match inout featues of next layer\n        self.fc3 = nn.Linear(5,6) # third layer\n\n    def forward(self,x):\n        x = torch.relu(self.fc1(x))\n        x = torch.relu(self.fc2(x))\n        x = torch.sigmoid(self.fc3(x))\n        return x\n    \n\nmodel = NeuralNetwork()\n\nmodel\n\n\noutput:\nNeuralNetwork(\n  (fc1): Linear(in_features=1, out_features=2, bias=True)\n  (fc2): Linear(in_features=3, out_features=4, bias=True)\n  (fc3): Linear(in_features=5, out_features=6, bias=True)\n)\n\nit didnt give me any error i ran this code block in kaggle notebook\nYou're absolutely right to be confused about why this code runs without errors! Let me clarify what's happening and why you're not seeing an error yet.\n\nWhy No Error Occurs (Yet)\nClass Definition vs Instantiation:\n\nWhen you define the NeuralNetwork class and create an instance with model = NeuralNetwork(), you're just defining the architecture\n\nPyTorch only checks dimensions when you actually run data through the network (during the forward pass)\n\nWhat You've Done So Far:\n\nCreated the model architecture definition\n\nInitialized the model object\n\nBut haven't actually passed any data through it\n\nThe Output You See:\n\npython\nNeuralNetwork(\n  (fc1): Linear(in_features=1, out_features=2, bias=True)\n  (fc2): Linear(in_features=3, out_features=4, bias=True)\n  (fc3): Linear(in_features=5, out_features=6, bias=True)\n)\nThis is just PyTorch showing you the structure of your model - not verifying it works!\n\nWhen the Error Will Appear\nThe error will occur when you try to actually use the network:\n\n\n> **python# This will FAIL because of dimension mismatchinput_tensor = torch.tensor([[1.0]])  # shape [1, 1]output = model(input_tensor)  # This is where you'll get the errorYou'll get:textRuntimeError: mat1 and mat2 shapes cannot be multiplied (1x2 and 3x4)Why PyTorch Works This Way**\n\n\nFlexibility: PyTorch allows dynamic network architectures\n\nLazy Evaluation: Checks are done at runtime, not at definition time\n\nAdvanced Use Cases: Some networks might change their architecture dynamically","metadata":{}},{"cell_type":"markdown","source":"## correcting the neural network code","metadata":{}},{"cell_type":"code","source":"class NeuralNetwork(nn.Module): # create class\n    def __init__(self):\n        super(NeuralNetwork,self).__init__()\n        self.fc1 = nn.Linear(1,2) # first layer \n        self.fc2 = nn.Linear(2,4) # second layer\n        self.fc3 = nn.Linear(4,6) # third layer\n\n    def forward(self,x):\n        x = torch.relu(self.fc1(x))\n        x = torch.relu(self.fc2(x))\n        x = torch.sigmoid(self.fc3(x))\n        return x\n    \n\nmodel = NeuralNetwork()\n\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T17:03:57.277557Z","iopub.execute_input":"2025-07-06T17:03:57.277788Z","iopub.status.idle":"2025-07-06T17:03:57.348921Z","shell.execute_reply.started":"2025-07-06T17:03:57.277768Z","shell.execute_reply":"2025-07-06T17:03:57.348334Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"NeuralNetwork(\n  (fc1): Linear(in_features=1, out_features=2, bias=True)\n  (fc2): Linear(in_features=2, out_features=4, bias=True)\n  (fc3): Linear(in_features=4, out_features=6, bias=True)\n)"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"## above we created model architecture defination\n\n## Also intialized the model object","metadata":{}},{"cell_type":"markdown","source":"## Passing the data through the model\n","metadata":{}},{"cell_type":"code","source":"input_tensor = torch.tensor([[1.0]])\n\noutput = model(input_tensor)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T17:04:08.001462Z","iopub.execute_input":"2025-07-06T17:04:08.001979Z","iopub.status.idle":"2025-07-06T17:04:08.060312Z","shell.execute_reply.started":"2025-07-06T17:04:08.001939Z","shell.execute_reply":"2025-07-06T17:04:08.059786Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T17:04:10.077789Z","iopub.execute_input":"2025-07-06T17:04:10.078491Z","iopub.status.idle":"2025-07-06T17:04:10.126381Z","shell.execute_reply.started":"2025-07-06T17:04:10.078464Z","shell.execute_reply":"2025-07-06T17:04:10.125842Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"tensor([[0.3513, 0.4842, 0.4907, 0.4657, 0.4675, 0.5856]],\n       grad_fn=<SigmoidBackward0>)"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"data_inputs = torch.randn(100,1) # dummy data\n\ntargets = torch.randint(0,2,(100,6)).float() # target of 0,1  with 100 ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T17:25:17.307225Z","iopub.execute_input":"2025-07-06T17:25:17.307999Z","iopub.status.idle":"2025-07-06T17:25:17.360187Z","shell.execute_reply.started":"2025-07-06T17:25:17.307975Z","shell.execute_reply":"2025-07-06T17:25:17.359441Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"Parameters:\n\nParameter\tMeaning\tExample (0, 2)\n\nlow\tInclusive lower bound\t0 (smallest possible value)\n\nhigh\tExclusive upper bound\t2 (generates values below 2)\n\nsize\tShape of output tensor\t(100, 1) → 100 rows × 1 column\n","metadata":{}},{"cell_type":"code","source":"# criterion = nn.BCELoss() #binarycross-entropy loss for binary classification\n#                          # or multi-label classification\n\ncriterion = nn.BCEWithLogitsLoss()  # Remove sigmoid from forward()\n\noptimizer = torch.optim.Adam(model.parameters(),lr = 0.001)\n\nepoches = 20 # number of iteration through entire system","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T17:31:03.952659Z","iopub.execute_input":"2025-07-06T17:31:03.953351Z","iopub.status.idle":"2025-07-06T17:31:03.957407Z","shell.execute_reply.started":"2025-07-06T17:31:03.953328Z","shell.execute_reply":"2025-07-06T17:31:03.956806Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"## traning\n1.optimizer.zero_grad() for clearing previous gradients\n\n2.model = inputs for forwardpass \n\n3.loss computation - loss = critireon(outputs,targets)\n\n4. loss.backward() for gradient computaion for ALL Weights\n\n5. optimizer.step() for weights updates","metadata":{}},{"cell_type":"code","source":"for epoch in range(epoches):\n    optimizer.zero_grad()\n    outputs = model(data_inputs)\n    loss = criterion(outputs,targets)\n    loss.backward()\n    optimizer.step()\n    if (epoch+1)% 5 == 0:\n        print(f\" Epoch[{epoch+1/epoches}],loss:{loss.item():.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T17:31:06.811007Z","iopub.execute_input":"2025-07-06T17:31:06.811452Z","iopub.status.idle":"2025-07-06T17:31:06.850037Z","shell.execute_reply.started":"2025-07-06T17:31:06.811434Z","shell.execute_reply":"2025-07-06T17:31:06.849273Z"}},"outputs":[{"name":"stdout","text":" Epoch[4.05],loss:0.7310\n Epoch[9.05],loss:0.7307\n Epoch[14.05],loss:0.7304\n Epoch[19.05],loss:0.7301\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}